# Отчет по лабораторной работе №7
## Исследование параметров генерации текста в Large Language Models

### 1. Цель работы
Практическое знакомство с архитектурой Large Language Models (LLM) через экспериментирование с ключевыми параметрами генерации текста: Temperature, Top-k и Top-p. Исследование влияния этих параметров на качество и разнообразие генерируемого контента.

### 2. Используемые инструменты и библиотеки
- **Python 3.8+**
- **Основные библиотеки**:
    - `transformers` - для работы с предобученными моделями
    - `torch` - фреймворк глубокого обучения
    - `matplotlib`, `seaborn` - для визуализации результатов
    - `numpy` - для работы с массивами
- **Тестируемые модели** (доступные в программе):
    - distilgpt2 (82M параметров)
    - gpt2 (124M параметров)
    - DialoGPT-small (117M параметров)
    - TinyLlama-1.1B (1.1B параметров)

### 3. Архитектура программы

#### 3.1 Основные классы

**1. ModelManager**
```python
# Отвечает за управление моделями:
- Загрузка и выгрузка моделей из памяти
- Управление кэшем моделей на диске
- Проверка доступности моделей
- Автоматическое определение устройства (CPU/GPU)
```

**2. ExperimentRunner**
```python
# Проводит эксперименты с генерацией:
- Базовая генерация текста
- Эксперименты с параметром Temperature
- Исследование Top-k и Top-p сэмплинга
- Тестирование на различных типах промптов
```

#### 3.2 Ключевые функции

**Загрузка модели**:
- Автоматическое определение доступного устройства
- Поддержка как CPU, так и GPU
- Кэширование моделей для повторного использования
- Обработка отсутствующих токенов (pad_token)

**Генерация текста**:
```python
def generate_text(self, prompt, **kwargs):
    # Поддерживаемые параметры:
    # - max_new_tokens: максимальное количество новых токенов
    # - temperature: контролирует случайность
    # - top_k: ограничивает выбор k наиболее вероятными токенами
    # - top_p: nucleus sampling
    # - do_sample: включить/выключить сэмплинг
```

### 4. Проведенные эксперименты

#### 4.1 Исследование параметра Temperature
**Цель**: Изучить влияние параметра Temperature на разнообразие генерируемого текста.

**Параметры тестирования**:
- Промпт: "The future of artificial intelligence is"
- Значения Temperature: [0.1, 0.4, 0.7, 1.0]
- Фиксированные параметры: max_new_tokens=50, top_k=50

**Результаты**:
- **Temperature = 0.1**: Наиболее предсказуемый и консервативный текст, повторяет частые паттерны
- **Temperature = 0.4**: Баланс между предсказуемостью и креативностью
- **Temperature = 0.7**: Увеличение разнообразия, более творческие ответы
- **Temperature = 1.0**: Максимальная случайность, иногда бессвязный текст

**Визуализация**: График зависимости длины текста от значения Temperature

#### 4.2 Эксперименты с Top-k и Top-p
**Цель**: Исследовать методы ограничения словаря при генерации.

**Конфигурации тестирования**:
1. **Top-k сэмплинг**:
    - Top-k=5: Строгий отбор, высокое качество
    - Top-k=50: Более разнообразный вывод

2. **Top-p (nucleus) сэмплинг**:
    - Top-p=0.3: Консервативный выбор
    - Top-p=0.9: Творческая генерация

3. **Комбинации параметров**:
    - k=50, p=0.9: Баланс качества и разнообразия
    - k=10, p=0.5: Консервативный сбалансированный подход
    - k=100, p=0.95: Максимально разнообразная генерация

#### 4.3 Тестирование различных типов промптов
**Цель**: Оценить способность модели обрабатывать разные типы запросов.

**Типы промптов**:
1. **Утверждения**: "Python is the best language because"
2. **Вопросы**: "What is the capital of France?"
3. **Творческие задания**: "Write a short poem about a robot:"
4. **Списки**: "List 5 fruits:\n1."

### 5. Ключевые наблюдения и выводы

#### 5.1 Влияние Temperature
- **Низкие значения (0.1-0.3)**: Подходят для задач, требующих точности и предсказуемости
- **Средние значения (0.4-0.7)**: Оптимальны для большинства творческих задач
- **Высокие значения (0.8-1.0)**: Могут генерировать нетривиальные идеи, но рискуют потерять связность

#### 5.2 Сравнение Top-k и Top-p
- **Top-k**: Проще в настройке, гарантирует выбор из k лучших вариантов
- **Top-p**: Более адаптивный, динамически определяет размер словаря
- **Комбинация**: Top-p=0.9 с Top-k=40-50 дает наилучший баланс

#### 5.3 Производительность моделей
- **Легкие модели (distilgpt2, gpt2)**: Быстрая генерация, подходят для экспериментов
- **Более тяжелые модели (TinyLlama)**: Качественнее контент, но требуют больше ресурсов

### 6. Технические особенности реализации

#### 6.1 Оптимизация памяти
- Автоматическая очистка кэша CUDA при выгрузке моделей
- Возможность удаления скачанных моделей для экономии места
- Использование float16 на GPU для экономии памяти

#### 6.2 Обработка ошибок
- Проверка наличия загруженной модели перед генерацией
- Обработка отсутствующих pad_token
- Логирование прогресса загрузки

#### 6.3 Пользовательский интерфейс
- Интерактивное меню с подсказками
- Визуализация результатов экспериментов
- Статус загрузки и использования моделей

### 7 Результаты эксперимента: Влияние параметра Temperature на генерацию текста

## Temperature = 0.1
**Результат:**  
The future of artificial intelligence is uncertain.

**Анализ:**
- Распределение вероятностей очень острое → почти всегда выбирается самый вероятный токен
- Повторение стандартных, часто встречающихся фраз
- Отсутствие креативности

**Вывод:**
- Максимальная предсказуемость
- Высокая связность
- Риск банальности и повторов

---

## Temperature = 0.4
**Результат:**  
…in the hands of the next generation of scientists…

**Анализ:**
- Пик распределения сохраняется, но редкие токены могут участвовать
- Текст развивается логично, появляются более содержательные конструкции
- Минимальные повторы, связность высокая

**Вывод:**
- Оптимальный режим для информативного текста
- Баланс контроля и разнообразия
- Минимальные галлюцинации

---

## Temperature = 0.7
**Результат:**  
…all about the future of business…

**Анализ:**
- Модель активно использует менее вероятные токены
- Появляется переход между темами (AI → бизнес → компании → мир)
- Текст становится «живым», появляются рассуждения

**Вывод:**
- Подходит для эссе, рассуждений, творческого текста
- Высокая вариативность при сохранении связности
- Иногда логика может расплываться, возможны неточности

---

## Temperature = 1.0
**Результат:**  
…now very possible," he said. Samantha Anderson, a research associate…

**Анализ:**
- Распределение почти равномерное, редкие токены часто выбираются
- Модель генерирует имена и источники → галлюцинации
- Логика нарушается, появляются неожиданные переходы

**Вывод:**
- Подходит для художественного и креативного текста
- Высокий риск неверных фактов и бессвязных предложений
- Достоверность ↓, креативность ↑

---

## Сравнительная таблица

| Temperature | Поведение модели      | Наблюдаемое в тексте                  |
|------------|---------------------|--------------------------------------|
| 0.1        | Почти детерминированная | Повторы, клише                        |
| 0.4        | Контролируемая       | Чёткая логика, развитие мысли         |
| 0.7        | Сбалансированная     | Рассуждения, креативные переходы     |
| 1.0        | Хаотичная           | Галлюцинации, имена и источники      |


### 8. Рекомендации по использованию

#### Для учебных целей:
1. Начинать с distilgpt2 для быстрых экспериментов
2. Использовать Temperature=0.7 для сбалансированной генерации
3. Комбинировать Top-k=50 и Top-p=0.9

#### Для продакшн-задач:
1. Выбирать более крупные модели для качества
2. Настраивать параметры под конкретную задачу
3. Добавлять пост-обработку сгенерированного текста

### 9. Возможные улучшения
1. Добавление поддержки большего количества моделей
2. Реализация бенчмарков для сравнения моделей
3. Добавление метрик оценки качества генерации
4. Поддержка потоковой генерации текста
5. Интеграция с внешними API для расширенных возможностей

### 10. Заключение
Работа успешно демонстрирует принципы работы LLM и влияние различных параметров на генерацию текста. Реализованная программа позволяет наглядно исследовать:
- Зависимость качества текста от сложности модели
- Влияние Temperature на креативность
- Различия между методами сэмплинга (Top-k vs Top-p)
- Способность моделей обрабатывать различные типы запросов

Полученные знания могут быть применены для тонкой настройки LLM под конкретные задачи генерации текста.